{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/viksit-siddhant/speechClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, threading\n",
    "import numpy as np\n",
    "import random\n",
    "import torchaudio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from speechClass.models.deepSpectrum import Model\n",
    "from speechClass.utils import Dataset\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"/content/drive/MyDrive/data.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = torchaudio.load('data/LeNormand/TD/kevin.wav')[0]\n",
    "spec = torchaudio.transforms.Spectrogram(512)(audio)\n",
    "print(spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    data = np.load(f)\n",
    "    czech_x = data['czech_x']\n",
    "    czech_y = data['czech_y']\n",
    "    english_x = data['english_x']\n",
    "    english_y = data['english_y']\n",
    "    lenormand_x = data['lenormand_x']\n",
    "    lenormand_y = data['lenormand_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to 3 channels\n",
    "lenormand_x = np.concatenate((lenormand_x, lenormand_x, lenormand_x), axis=1)\n",
    "czech_x = np.concatenate((czech_x, czech_x, czech_x), axis=1)\n",
    "english_x = np.concatenate((english_x, english_x, english_x), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "lenormand_neg_x = lenormand_x[lenormand_y.reshape((-1)) == 0]\n",
    "lenormand_neg_y = lenormand_y[lenormand_y.reshape((-1)) == 0]\n",
    "czech_neg_x = czech_x[czech_y.reshape((-1)) == 0]\n",
    "czech_neg_y = czech_y[czech_y.reshape((-1)) == 0]\n",
    "czech_pos_x = czech_x[czech_y.reshape((-1)) == 1]\n",
    "czech_pos_y = czech_y[czech_y.reshape((-1)) == 1]\n",
    "\n",
    "def inflate(x,y,target_len):\n",
    "    num_samples = max(len(x), target_len)\n",
    "    samples = np.random.randint(0, len(x), num_samples-len(x))\n",
    "    x = np.concatenate((x, x[samples]))\n",
    "    y = np.concatenate((y, y[samples]))\n",
    "    return x,y\n",
    "\n",
    "num_samples = max(len(lenormand_neg_x), len(czech_neg_x), len(czech_pos_x))\n",
    "lenormand_neg_x, lenormand_neg_y = inflate(lenormand_neg_x, lenormand_neg_y, num_samples)\n",
    "czech_neg_x, czech_neg_y = inflate(czech_neg_x, czech_neg_y, num_samples)\n",
    "czech_pos_x, czech_pos_y = inflate(czech_pos_x, czech_pos_y, 2*num_samples)\n",
    "\n",
    "train_data = Dataset(np.concatenate((lenormand_neg_x, czech_neg_x, czech_pos_x)), np.concatenate((lenormand_neg_y, czech_neg_y, czech_pos_y)))\n",
    "dataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = m.get_data(dataloader)\n",
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(feat, train_data.y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules import activation\n",
    "from torchvision import transforms\n",
    "\n",
    "dataset = torch.utils.data.ConcatDataset([czech,english,lenormand])\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "convmod = ConvModel([1,n_mfcc,maxlen])\n",
    "\n",
    "opt = torch.optim.Adam(convmod.parameters(), lr=0.001)\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=0,translate=(0.66,0.66)),\n",
    "    transforms.GaussianBlur(3, sigma=(0.1, 0.6)),\n",
    "    ])\n",
    "\n",
    "loss = torch.nn.NLLLoss(weight=torch.tensor([czech.num_pos,len(czech)-czech.num_pos+len(english)+len(lenormand)]).to(\"cuda\",dtype=torch.float))\n",
    "\n",
    "def train(model, train_loader, test_loader, loss, opt, epochs,transformer = None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Loading model to \", device)\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_steps = len(train_loader)\n",
    "        counter = 0\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device,dtype=torch.float)\n",
    "            y = y.to(device,dtype=torch.long)\n",
    "            y = torch.flatten(y)\n",
    "            x = transformer(x)\n",
    "            opt.zero_grad()\n",
    "            pred = model(x)\n",
    "            l = loss(pred, y)\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "            train_loss += l.item()\n",
    "            print(f\"Step {counter+1} of {train_steps}\", end='\\r')\n",
    "            counter+=1\n",
    "        print(\"\")\n",
    "        print(\"Train Loss: \",train_loss)\n",
    "        model.eval()\n",
    "        if test_loader is None:\n",
    "            continue\n",
    "        test_loss = 0\n",
    "        counter = 0\n",
    "        num_correct_predictions = 0\n",
    "        test_steps = len(test_loader)\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x = x.to(device,dtype=torch.float)\n",
    "                y = y.to(device,dtype=torch.long)\n",
    "                y = torch.flatten(y)\n",
    "                pred = model(x)\n",
    "                l = loss(pred, y)\n",
    "                y = torch.flatten(y)\n",
    "                test_loss += l.item()\n",
    "\n",
    "                pred = torch.argmax(pred, dim=1)\n",
    "                num_correct_predictions += torch.sum(pred == y).item()\n",
    "                print(f\"Step {counter+1} of {test_steps}\", end='\\r')\n",
    "                counter+=1\n",
    "        print(\"\")\n",
    "        print(f\"Test Loss: {test_loss}, Accuracy: {num_correct_predictions/len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(torch.cuda.is_available())\n",
    "convmod.unfreeze()\n",
    "train(convmod, train_loader, test_loader, loss, opt, 10, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot 10 random images from model.train_x\n",
    "\n",
    "figs, axs = plt.subplots(2,5, figsize=(15,6))\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        axs[i,j].imshow(train_data[random.randint(0,len(train_data))][0][0], cmap='viridis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenormand = LeNormandData(16000, 32,32)\n",
    "#print(model.train_x[0])\n",
    "\n",
    "#Plot 10 random images from model.train_x\n",
    "\n",
    "figs, axs = plt.subplots(2,5, figsize=(15,6))\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        axs[i,j].imshow(lenormand[np.random.randint(0,len(lenormand))][0].squeeze())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = 0.1\n",
    "train_ln,test_ln = torch.utils.data.random_split(lenormand,[int(train_fraction*len(lenormand)),len(lenormand)-int(train_fraction*len(lenormand))])\n",
    "train_ln = torch.utils.data.DataLoader(train_ln, batch_size=32, shuffle=True)\n",
    "test_ln = torch.utils.data.DataLoader(test_ln, batch_size=32, shuffle=True)\n",
    "convmod.freeze(1)\n",
    "\n",
    "train(convmod, train_ln, test_ln, loss, opt, 20, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_loader = torch.utils.data.DataLoader(lenormand, batch_size=32, shuffle=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_correct_0 = 0\n",
    "num_correct_1 = 0\n",
    "num_0 = 0\n",
    "num_1 = 0\n",
    "for x,y in ln_loader:\n",
    "    x = x.to(device,dtype=torch.float)\n",
    "    y = y.numpy().flatten()\n",
    "    with torch.no_grad():\n",
    "        pred = np.argmax(convmod(x).cpu().numpy(),axis=1)\n",
    "        num_correct_0 += np.sum((pred < 0.5) & (y == 0))\n",
    "        num_correct_1 += np.sum((pred >= 0.5) & (y == 1))\n",
    "        print(pred)\n",
    "        print(y)\n",
    "        num_0 += np.sum(y == 0)\n",
    "        num_1 += np.sum(y == 1)\n",
    "\n",
    "print(f\"Accuracy on zero: {num_correct_0/num_0}\")\n",
    "print(f\"Accuracy on one: {num_correct_1/num_1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('speechClass': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b91e72974164e2d01c3ab4c2fedc06e339e111d9a2a09c8eaeaab510c7412d76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
